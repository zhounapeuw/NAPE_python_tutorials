{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn import metrics\n",
    "from statsmodels.api import OLS\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r'C:\\Users\\The_Iron_Maiden\\Documents\\Python Scripts\\College.csv'\n",
    "\n",
    "college_data = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    CRIM - per capita crime rate by town\n",
    "    ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "    INDUS - proportion of non-retail business acres per town.\n",
    "    CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "    NOX - nitric oxides concentration (parts per 10 million)\n",
    "    RM - average number of rooms per dwelling\n",
    "    AGE - proportion of owner-occupied units built prior to 1940\n",
    "    DIS - weighted distances to five Boston employment centres\n",
    "    RAD - index of accessibility to radial highways\n",
    "    TAX - full-value property-tax rate per $10,000\n",
    "    PTRATIO - pupil-teacher ratio by town\n",
    "    B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "    LSTAT - % lower status of the population\n",
    "    MEDV - Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r'C:\\Users\\The_Iron_Maiden\\Documents\\Python Scripts\\Boston.csv'\n",
    "\n",
    "boston_data = pd.read_csv(csv_path)\n",
    "boston_data.keys()\n",
    "\n",
    "num_samples = boston_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__first problem wants us to build a model predicting median value from lstat; let's look at the relationship__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot relationship btw lstat (% of population with lower status) and median home value (in 1000's)\n",
    "ax = sns.scatterplot(x=\"lstat\", y=\"medv\", data=boston_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use statsmodel to get a summary of a fitted linear model\n",
    "\n",
    "https://stats.stackexchange.com/questions/146804/difference-between-statsmodel-ols-and-scikit-linear-regression\n",
    "\n",
    "scikit learn is geared towards predictive modeling, so doesn't have an R summary equivalent for LR\n",
    "\n",
    "_\"Linear regression is in its basic form the same in statsmodels and in scikit-learn.\"_\n",
    "\n",
    "_\"Statsmodels follows largely the traditional model where we want to know __how well a given model fits the data, and what variables \"explain\" or affect the outcome, or what the size of the effect is__. Scikit-learn follows the machine learning tradition where the main supported task is __chosing the \"best\" model for prediction__.\"_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the dependent and independent variables\n",
    "simple_LR_y = pd.DataFrame(boston_data['medv'])\n",
    "simple_LR_x = pd.DataFrame(boston_data['lstat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_X = sm.add_constant(simple_LR_x) # THIS IS VERY IMPORTANT - ADDS CONSTANT for INTERCEPT\n",
    "\n",
    "OLS(simple_LR_y,sm_X).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use scikit learn linear regression to make a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "# fit the LR\n",
    "regr.fit(simple_LR_x, simple_LR_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/a-beginners-guide-to-linear-regression-in-python-with-scikit-learn-83a8f7ae2b4f\n",
    "\n",
    "print('Intercept: \\n', regr.intercept_[0])\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a vector of x values that span the limits of the dataset\n",
    "padding = 3\n",
    "x_data_min = simple_LR_x.min()['lstat']\n",
    "x_data_max = simple_LR_x.max()['lstat']\n",
    "x_line = np.arange(x_data_min-padding,x_data_max+padding)\n",
    "# predict y values for these x values\n",
    "y_line_pred = regr.predict(x_line.reshape(-1, 1))\n",
    "# we'll use these x and y values to plot a line representing the best fit regression line from our model\n",
    "\n",
    "ax = sns.scatterplot(x=\"lstat\", y=\"medv\", data=boston_data)\n",
    "plt.plot(x_line, y_line_pred, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some insight on the model: \n",
    "\n",
    "the lower lstat datapoints introduce nonlinearity in the data. They are harder to predict and also overestimates predictions across lstat values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .predict() to calculate the model's medv estimates for each data point's lstat\n",
    "y_pred = regr.predict(simple_LR_x)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(simple_LR_y, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(simple_LR_y, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(simple_LR_y, y_pred)))\n",
    "print('R^2:', metrics.r2_score(simple_LR_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate residual sum of squares (RSS)\n",
    "\n",
    "rss = ( (simple_LR_y - y_pred)**2 ).sum(axis = 0)\n",
    "print('RSS: ' + str(rss))\n",
    "\n",
    "print('')\n",
    "\n",
    "rse = ( (1/(num_samples-2)) * rss )**0.5\n",
    "print('RSE: ' + str(rse))\n",
    "\n",
    "print('')\n",
    "\n",
    "tss = np.sum( (simple_LR_y - np.mean(simple_LR_y))**2 )\n",
    "r_squared = 1 - (rss/tss)\n",
    "print('R^2: ' + str(r_squared))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the dependent and independent variables\n",
    "multiple_LR_y = pd.DataFrame(boston_data['medv'])\n",
    "multiple_LR_x = pd.DataFrame(boston_data.drop(['Unnamed: 0','medv'] , axis='columns')) # get rid of irrelevant and outcome columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_X_mult = sm.add_constant(multiple_LR_x) # THIS IS VERY IMPORTANT - ADDS CONSTANT for INTERCEPT\n",
    "\n",
    "OLS(multiple_LR_y,sm_X_mult).fit().summary()\n",
    "\n",
    "# we get similar coefficient as R's book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NOX - nitric oxides concentration (parts per 10 million)__\n",
    "\n",
    "__lstat value changed - potentially b/c of correlations with other variables__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### interaction terms\n",
    "\n",
    "Below, we'll use stats model formula to define the dependent, independent variables, interactions, and any transformations. This roughly replicates how one would write the model formulas in R.\n",
    "\n",
    "The language we use is called Patsy which takes the form of a string that is interpretted and converted to an equation that statsmodels uses to generate the linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smf.ols(formula='medv ~ lstat * age', data=boston_data).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The above warning indicates collinearity between variables; let's see how correlated lstat and age are:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pear_r = stats.pearsonr(boston_data['lstat'], boston_data['age'])\n",
    "\n",
    "sns.scatterplot(boston_data['lstat'], boston_data['age']).set_title(\"Pearson R = \" + str(pear_r[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "last thing to do is __apply nonlinear functions to regression variables__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the I() evaluates its contents and sends that to python as a single variable\n",
    "\n",
    "# https://stackoverflow.com/questions/16665833/statsmodels-specifying-non-linear-regression-models-using-patsy\n",
    "# https://patsy.readthedocs.io/en/latest/builtins-reference.html\n",
    "\n",
    "smf.ols(formula='medv ~ lstat + I(lstat**2)', data=boston_data).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
