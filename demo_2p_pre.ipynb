{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-photon imaging Demo\n",
    "\n",
    "This notebook contains exercises split across multiple lessons that span the following primary topics\n",
    "* conditionals\n",
    "* lists\n",
    "* loops\n",
    "* numpy\n",
    "* visualization\n",
    "\n",
    "The exercise modules are centered around analysis of neuroscience 2-photon imaging data, which involves recording __two-dimensional__ (X/Y space) changes in brightness of activity-dependent fluorescent proteins that are expressed in cells of interest. Typically the activity data stream consists of a 3-dimensional dataset (X, Y, and time; i.e. a video). For this particular dataset (acquired by Dr. Vijay Namboodiri), the data were collected through a GRIN lens of GCaMP6s-expressing neurons in orbitofrontal cortex. The data consists of single frames in the format of tifs, where each tif file is a sample collected across time.\n",
    "\n",
    "The exercises follow a sequence starting from identifying the list of files corresponding to each frame, filtering the list for particular frame numbers, loading the frames into numpy arrays, and visualizing the images. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import tifffile as tiff\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = r'sample_data\\VJ_OFCVTA_7_260_D6_cropped'\n",
    "search_path = os.path.join(file_dir,\"*.tif\")\n",
    "\n",
    "print(search_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The * indicates a \"wildcard\" that represents any number or type of characters that could be in that specific location in the string\n",
    "\n",
    "For example the variable `search_path` paired with the glob function below, will search for file paths that start with `file_dir` and end in `.tif`. As long as those two conditions are met, it won't matter what the contents in between are (hence the * wildcard).\n",
    "\n",
    "Glob is a nice built-in module that finds paths and files based on supplied search parameters. If there are multiple files that satisfy the glob search argument, it will return a list of paths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_list = sorted(glob.glob(search_path))\n",
    "glob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(glob_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Part 1, Exercise 1: Maybe we don't want to load in all the files above. What can we do to filter the list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_first_50 = glob_list[:50]\n",
    "print(glob_first_50)\n",
    "\n",
    "glob_last_50 = glob_list[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how we get every other file starting from the 0th (even files). \n",
    "glob_every_other_even = glob_list[::2]\n",
    "glob_every_other_even\n",
    "\n",
    "# How do we get every odd file? Print the contents of `glob_every_other` and use the len() function to confirm you filtered the right files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lists Part 2, Exercise 1 (Conditional and list combined): Removing items from lists/Removing frames from load lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_item = 'sample_data\\\\VJ_OFCVTA_7_260_D6_cropped\\\\VJ_OFCVTA_7_260_D6_cropped0046.tif'\n",
    "\n",
    "if remove_item in glob_every_other_even: # exercise goal: plug in the right variables\n",
    "    print('Removing item')\n",
    "    glob_every_other_even.remove(remove_item)\n",
    "else:\n",
    "    print('Item not present in list!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_every_other_even[20:30]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lists Part 2, Exercise 2 (Lists, conditionals, Loops, and List-comprehension): Filtering lists with list comprehension and removing frames from load list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in glob_every_other_even:\n",
    "    if 'cropped000' in entry:\n",
    "        print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_list = []\n",
    "for entry in glob_every_other_even:\n",
    "    if 'cropped000' not in entry:\n",
    "        filtered_list.append(entry) \n",
    "\n",
    "filtered_list[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to recreate the above statement using a more pythonic format, list comprehension. It should compress the code in the cell above into one line! assign the output to the `filtered_list_compreh` variable to make sure the output matches above.\n",
    "\n",
    "Use the following format: [ `x` for `x` in `list` if `filter_item` not in `x` ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_list_compreh = [ entry for entry in glob_every_other_even if 'cropped000' not in entry ]\n",
    "filtered_list_compreh[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with 3D and 2D arrays (numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_frame = tiff.imread(glob_every_other_even[0])\n",
    "first_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(first_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tiff.imread(glob_every_other_even[40]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy exercise 3: Let's load up all 2p frames from the glob list into a numpy array. \n",
    "\n",
    "Using the shape method, figure out what argument you need to pass into the np.empty function in order to initialize the numpy array for populating the frame data.\n",
    "\n",
    "Then as we loop through each file that's loaded in from the file list, figure out which position the frame_counter needs to be in to properly slot in each loaded frame into the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2p = np.empty([len(glob_every_other_even),142,247])\n",
    "frame_counter = 0\n",
    "for frame_path in glob_every_other_even:\n",
    "    data_2p[frame_counter,:,:] = tiff.imread(frame_path)\n",
    "    frame_counter += 1 # =+ doesn't work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.mean(data_2p, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2p_mean = np.mean(data_2p, axis=0)\n",
    "\n",
    "data_2p_mean.argmax()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Exercise 3: plotting max point on a 2-photon imaging 2D heatmap \n",
    "\n",
    "** Hint: Research and use the function `np.unravel_index()`. You'll also need to make use of the method `.shape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_xy_coord = np.unravel_index(data_2p_mean.argmax(), data_2p_mean.shape) \n",
    "\n",
    "plt.imshow(np.mean(data_2p, axis=0))\n",
    "plt.plot(max_xy_coord[1], max_xy_coord[0], marker=\"o\", markersize=10, markerfacecolor=\"red\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Exercise 4: Cropping/slicing data before heatmap plot\n",
    "\n",
    "Use numpy array slicing to visualize a subset of the imaging FOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2p_cropped = data_2p[:, 55:80, 50:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.mean(data_2p_cropped, axis=0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same thing as above, but with posthoc limitations of the plot view. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.mean(data_2p, axis=0))\n",
    "plt.xlim([50,200])\n",
    "plt.ylim([80,55])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if your goal is to save memory and computing power, this strategy is not the ideal. But if you need flexibility and are dealing manageable datasets, this strategy is acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nape_python_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b42ec29e0d042ab71033bfd4ca780b7a8291c7b26e4c3b3923625b510f7afa3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
