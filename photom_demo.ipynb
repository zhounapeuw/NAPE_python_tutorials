{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./helpers')\n",
    "from py_fp import tidy_tdt_extract_and_tidy\n",
    "\n",
    "dir_raw = r'D:\\non_2p\\Brandy\\raw'\n",
    "dir_extracted = r'D:\\non_2p\\Brandy\\extracted'\n",
    "\n",
    "tidy_tdt_extract_and_tidy(dir_raw, dir_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'hcp_37_B_11092022'\n",
    "session_info_path = os.path.join(dir_extracted, f'{fname}_info.feather')\n",
    "\n",
    "data_path = os.path.join(dir_extracted, f'{fname}_streams_data.feather')\n",
    "data_info_path = os.path.join(dir_extracted, f'{fname}_streams_info.feather')\n",
    "\n",
    "epoc_data_path = os.path.join(dir_extracted, f'{fname}_epocs_data.feather')\n",
    "epoc_info_path = os.path.join(dir_extracted, f'{fname}_epocs_info.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_info = pd.read_feather(session_info_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## work on behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoc_data = pd.read_feather(epoc_data_path)\n",
    "epoc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoc_data['name'].unique() # grab unique condition names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab event times for condition 1\n",
    "event_one = epoc_data['onset'][epoc_data['name'] == 'PC1/'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work on tseries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab event times for all conditions via for loop\n",
    "event_times_dict = {}\n",
    "for event_name in epoc_data['name'].unique():\n",
    "    event_times_dict[event_name] = epoc_data['onset'][epoc_data['name'] == event_name].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_feather(data_path)\n",
    "data_info = pd.read_feather(data_info_path)\n",
    "fs = data_info['fs'][0] # assuming sampling rate is the same across channels\n",
    "\n",
    "data_405 = data[data['channel']=='_405A']['raw_au'].values\n",
    "data_465 = data[data['channel']=='_465A']['raw_au'].values\n",
    "\n",
    "tvec = np.linspace(0,len(data_405)/fs, len(data_405))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GuPPY version\n",
    "# function to fit control channel to signal channel\n",
    "def controlFit(control, signal):\n",
    "    \n",
    "    p = np.polyfit(control, signal, 1)\n",
    "    arr = (p[0]*control)+p[1]\n",
    "    return arr\n",
    "\n",
    "# function to compute deltaF/F using fitted control channel and filtered signal channel\n",
    "def deltaFF(signal, control):\n",
    "    \n",
    "    res = np.subtract(signal, control)\n",
    "    normData = np.divide(res, control)\n",
    "    #deltaFF = normData\n",
    "    normData = normData*100\n",
    "\n",
    "    return normData\n",
    "\n",
    "fitted_control = controlFit(data_405, data_465)\n",
    "corrected_data = deltaFF(data_465, fitted_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(tvec, data_405)\n",
    "plt.plot(tvec, data_465)\n",
    "plt.plot(tvec, fitted_control)\n",
    "plt.plot(tvec, corrected_data)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Fluorescence')\n",
    "#plt.xlim([0.5, tvec[-1]]) # test: how to get rid of artifact\n",
    "plt.legend(['405', '470', 'fit curve', 'corrected']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert behavioral event times to samples: to prepare for indexing and snipping out trial activity windows.\n",
    "\n",
    "#### Requires knowledge on: dictionaries and functions \n",
    "\n",
    "The data itself is not characterized by units of time, rather each item in the vector is a \"sample\" in the recording and does not hold any information on timing\n",
    "\n",
    "On the other hand our behavioral events are in units of time. Accordingly, to extract trial snippits from the photometry data, we need to figure out which sample corresponds to a given event time\n",
    "\n",
    "We can use this line of code : `np.argmin(abs(tvec - time))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'First event from condition one: {event_one[0]}')\n",
    "\n",
    "print(f\"The sample that corresponds to {event_one[0]} is {np.argmin(abs(tvec - event_one[0]))}\")\n",
    "\n",
    "print(f\"Sample {np.argmin(abs(tvec - event_one[0]))}'s time: {tvec[330439]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's extract the activity trace from one trial for demonstration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize start/end times for trial window\n",
    "event_window_time = np.array([-1, 10])\n",
    "event_window_samples = (event_window_time*fs).astype(int) # samples are integers\n",
    "\n",
    "# generate vector the maps time onto samples in the event trial\n",
    "trial_window_num_samples = event_window_samples[1] - event_window_samples[0]\n",
    "tvec_trial = np.linspace(event_window_time[0], event_window_time[1], trial_window_num_samples)\n",
    "\n",
    "# generate vector of every sample between start and end samples\n",
    "# then offset to specific event's window by adding the event sample\n",
    "trial_template_indices = np.arange(event_window_samples[0], event_window_samples[1])\n",
    "trial_samples = trial_template_indices + np.argmin(abs(tvec - event_one[0]))\n",
    "\n",
    "plt.plot(tvec_trial, corrected_data[trial_samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To analyze all trials, let's do some organization of the event conditions and trial times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the above code into a function\n",
    "def get_tvec_sample(tvec, time):\n",
    "    return np.argmin(abs(tvec - time))\n",
    "\n",
    "event_samples_dict = {}\n",
    "for condition_name in epoc_data['name'].unique(): # loop through conditions\n",
    "    \n",
    "    print(condition_name)\n",
    "    tmp_list = []\n",
    "    \n",
    "    # go through each event and compute the sample/frame that it occurred on (b/c the list is currently in seconds)\n",
    "    for event in event_times_dict[condition_name]: # loop through events\n",
    "        tmp_list.append(get_tvec_sample(tvec, event))\n",
    "        \n",
    "    # once we go through converting each time to sample, and add to a list iteratively,\n",
    "    # store that list to its corresponding condition in the dictionary\n",
    "    event_samples_dict[condition_name] = tmp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's analyze data from all trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bonus explanation\n",
    "def remove_trials_out_of_bounds(data_end, frame_events, start_samp, end_samp):\n",
    "\n",
    "    # list of booleans that indicates for each trial if it stays within the start/end samples of the entire recording\n",
    "    after_start_bool = (frame_events + start_samp) > start_samp # filters out (set to false) trials that would index before the first sample\n",
    "    before_end_bool = (frame_events + end_samp) < data_end # filters out trials that would index passed the last sample\n",
    "\n",
    "    \"\"\"\n",
    "    One pythonic way to combine the info above. Multiplying the lists generates a union of the two lists.\n",
    "    Then the if statement will allow trials that are True (falls within the entire recording) through\n",
    "    \"\"\"\n",
    "    keep_events = []\n",
    "    for idx, item in enumerate(after_start_bool*before_end_bool): \n",
    "        if item:\n",
    "            keep_events.append(frame_events[idx])\n",
    "\n",
    "    return np.array(keep_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove trials that have windows outside of entire recording, then extract data from each trial\n",
    "\n",
    "data_trial_dict = {}\n",
    "for condition_name in epoc_data['name'].unique(): # loop through conditions\n",
    "    \n",
    "    # use function above to remove trials where the trial window would extend outside of indexable data\n",
    "    event_samples_dict[condition_name] = remove_trials_out_of_bounds(len(tvec), \n",
    "                                                                     event_samples_dict[condition_name], \n",
    "                                                                     event_window_samples[0], \n",
    "                                                                     event_window_samples[-1])\n",
    "    \n",
    "    # initialize numpy array to populate with trial-extracted data\n",
    "    tmp_trial_array = np.empty([len(event_samples_dict[condition_name]), trial_window_num_samples])\n",
    "    \n",
    "    # use trial index template, offset with event sample, and extract trial data\n",
    "    for idx, event_sample in enumerate(event_samples_dict[condition_name]): # loop through events\n",
    "        tmp_trial_array[idx,:] = corrected_data[trial_template_indices + event_sample]\n",
    "    \n",
    "    # once data are fully populated, add to dictionary\n",
    "    data_trial_dict[condition_name] = tmp_trial_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data_trial_dict['PC1/'], aspect='auto')\n",
    "plt.ylabel('Fluorescence')\n",
    "plt.xlabel('Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tvec_trial, np.mean(data_trial_dict['Tick'], axis=0))\n",
    "plt.plot(tvec_trial, np.mean(data_trial_dict['PC1/'], axis=0))\n",
    "plt.ylabel('Fluorescence')\n",
    "plt.xlabel('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
