{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fiber Photometry Demo\n",
    "\n",
    "This notebook contains exercises split across multiple lessons that span the following primary topics\n",
    "* strings\n",
    "* conditionals\n",
    "* lists\n",
    "* pandas\n",
    "* dictionaries\n",
    "\n",
    "The exercise modules are centered around analysis of neuroscience fiber photometry data, which involves recording changes in brightness of activity-dependent fluorescent proteins that are expressed in cells of interest. Typically the activity data stream consists of a single vector time-series (i.e. fluorescence intensity measurements acquired across time). For this particular dataset (acquired by Dr. Adam Gordon-Fennell), animals were periodically allowed to consume liquid rewards in \"access periods.\" Both the onsets of the access periods and animal licks were recorded. The data consist of the following files:\n",
    "\n",
    "* *_events.csv : table where rows contain the event type (access period or lick) and time of occurrence (in seconds)\n",
    "* *_streams_session.csv : table where rows are samples acquired across time for the photometry recording. For each sample, the table details the channel, time, and fluorescence value\n",
    "\n",
    "The exercises follow a sequence starting from loading in (behavioral and neural stream) data from tabular files (excel CSVs), examining the data and extracting relevant data streams, preprocessing the data, and visualizing the activity. In the 2nd half of the exercises, we incorporate the behavioral data and generate activitt plots centered around the behavioral events. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = r'C:\\Users\\stuberadmin\\Documents\\GitHub\\NAPE_python_tutorials\\sample_data'\n",
    "fname = '2022_06_10_abb12'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditionals exercise 1: Detecting and loading data in different file formats.\n",
    "\n",
    "The cell below defines the absolute file path (`epoc_data_path`) for the behavioral data. Currently we are loading in the .feather file, which is just another file format that can store tabular data, as opposed to csv or xlsx formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note os.path.join is a function that simply merges and formats string arguments together such that they are compatible with other file loading functions\n",
    "epoc_data_path = os.path.join(fdir, f'{fname}_events.feather') \n",
    "epoc_data_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In the sample_data folder, we also have a csv version - try changing the behavioral data path above to the csv version, then edit the conditional in the cell below to load the csv.\n",
    "\n",
    " Notice that we are using the pandas package (abbreviated in the import code section at the top of this notebook as `pd`) to load the tabular data. We will learn more about it later, but pandas is a package that adds tabular data processing capabilities to python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'feather' in epoc_data_path:\n",
    "    print('loading feather file')\n",
    "    epoc_data = pd.read_feather(epoc_data_path)\n",
    "elif 'csv' in epoc_data_path:\n",
    "    print('loading csv file')\n",
    "    epoc_data = pd.read_csv(epoc_data_path)\n",
    "else:\n",
    "    print('Not a valid file type')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the .head() method on our pandas dataframe will show the top 5 entries.\n",
    "epoc_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditionals exercise 2: Checking contents of lists using conditionals and boolean operators"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preview of the behavioral data table above exercise doesn't really tell us how many behavioral conditions there are (event_id_char column) since there are so many row entries. We can have python look through all entries in the event_id_char column and tell us what unique entries there are by using the .unique() method. We will go over what coding concept a method is in later lessons, but for now, just know it will return all unique entries for a given pandas dataframe/series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_conditions = list(epoc_data['event_id_char'].unique()) # grab unique condition names\n",
    "event_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'access_period' in event_conditions and 'lick' in event_conditions:\n",
    "    print('Both conditions present')\n",
    "elif 'access_period' in event_conditions or 'lick' in event_conditions:\n",
    "    print('One out of the two conditions present')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas exercise 1: Exploring contents of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoc_data.nunique() # provides count of unique entries in each column\n",
    "epoc_data.info() # can identify if there is missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoc_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoc_data.iloc[95:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also get a sense of how many events (y dimension) there are. If we use the method `shape`, the first dimension outputted is y and the 2nd in x.\n",
    "epoc_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas exercise 2: Obtaining data from a dataframe column based on information in another column.\n",
    "\n",
    "We are working with neural activity data that was synchronized to events that happened during the recording. Our behavioral dataframe contains event times (event_ts) for two different types of behavooral events (access_periods and licks). Here let's figure out how to extract event times for a given condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab event times for condition 1\n",
    "event_one = epoc_data['event_ts'][epoc_data['event_id_char'] == 'access_period'].values\n",
    "event_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work on tseries data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas, math, and functions combined exercise: Correcting photometry traces with isosbestic channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(fdir, f'{fname}_streams_session.feather')\n",
    "\n",
    "data = pd.read_feather(data_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiber_id = '1' # 1 is NAcShell_medial; 2 is NAcShell_lateral\n",
    "\n",
    "data_405 = data['signal'][data['channel'] == '405'].values\n",
    "data_465 = data['signal'][data['channel'] == '465'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = data['time'][data['channel'] == '405'].values \n",
    "tvec_zeroed = tvec - data['time'][0] # for plotting trace starting from time 0\n",
    "\n",
    "fs = 1.0/np.mean(np.diff(tvec))\n",
    "\n",
    "print(tvec_zeroed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def controlFit(control, signal):\n",
    "    \n",
    "    # GuPPY version\n",
    "    # function to fit control channel to signal channel\n",
    "\n",
    "    p = np.polyfit(control, signal, 1)\n",
    "    arr = (p[0]*control)+p[1]\n",
    "    return arr\n",
    "\n",
    "\n",
    "def deltaFF(signal, control):\n",
    "    \n",
    "    # function to compute deltaF/F using fitted control channel and filtered signal channel\n",
    "\n",
    "    res = np.subtract(signal, control) # numerator of F(t)-f0\n",
    "    normData = np.divide(res, control) # (F(t)-f0)/F0\n",
    "    normData = normData*100\n",
    "\n",
    "    return normData\n",
    "\n",
    "fitted_control = controlFit(data_405, data_465) # this function would be helpful if we wanted to correct signals from multiple fluorophore channels\n",
    "corrected_data = deltaFF(data_465, fitted_control) # this function would be helpful everytime we needed to compute dF/F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(tvec_zeroed, data_405)\n",
    "plt.plot(tvec_zeroed, data_465)\n",
    "plt.plot(tvec_zeroed, fitted_control)\n",
    "plt.plot(tvec_zeroed, corrected_data)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Fluorescence')\n",
    "#plt.xlim([170, 400]) # we can zoom in to see how motion artifacts can be corrected for\n",
    "plt.legend(['405', '470', 'fit curve', 'corrected']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary Exercise: Dividing event times up into their respective conditions. These event times can then be organized into a dictionary for storage purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab event times for all conditions via for loop\n",
    "event_times_dict = {}\n",
    "for event_name in epoc_data['event_id_char'].unique():\n",
    "    event_times_dict[event_name] = epoc_data['event_ts'][epoc_data['event_id_char'] == event_name].values\n",
    "\n",
    "event_times_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert behavioral event times to samples: to prepare for indexing and snipping out trial activity windows.\n",
    "\n",
    "#### Requires knowledge on: dictionaries and functions \n",
    "\n",
    "The data itself is not characterized by units of time, rather each item in the vector is a \"sample\" in the recording and does not hold any information on timing\n",
    "\n",
    "On the other hand our behavioral events are in units of time. Accordingly, to extract trial snippits from the photometry data, we need to figure out which sample corresponds to a given event time\n",
    "\n",
    "We can use this line of code : `np.argmin(abs(tvec - time))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'First event from condition one: {event_one[0]}')\n",
    "\n",
    "print(f\"The sample that corresponds to {event_one[0]} is {np.argmin(abs(tvec - event_one[0]))}\")\n",
    "\n",
    "print(f\"Sample {np.argmin(abs(tvec - event_one[0]))}'s time: {tvec[4224]}\") # if dataset changes, replace number in tvec[4224] with calculated sample number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's extract the activity trace from one trial for demonstration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize start/end times for trial window\n",
    "event_window_time = np.array([-1, 10])\n",
    "event_window_samples = (event_window_time*fs).astype(int) # samples are integers\n",
    "\n",
    "# generate vector the maps time onto samples in the event trial\n",
    "trial_window_num_samples = event_window_samples[1] - event_window_samples[0]\n",
    "tvec_trial = np.linspace(event_window_time[0], event_window_time[1], trial_window_num_samples)\n",
    "\n",
    "# generate vector of every sample between start and end samples\n",
    "# then offset to specific event's window by adding the event sample\n",
    "trial_template_indices = np.arange(event_window_samples[0], event_window_samples[1])\n",
    "trial_samples = trial_template_indices + np.argmin(abs(tvec - event_one[0]))\n",
    "\n",
    "plt.plot(tvec_trial, corrected_data[trial_samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary lesson: To analyze all trials, let's do some organization of the event conditions and trial times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the above code into a function\n",
    "def get_tvec_sample(tvec, time):\n",
    "    return np.argmin(abs(tvec - time))\n",
    "\n",
    "event_samples_dict = {}\n",
    "for condition_name in epoc_data['event_id_char'].unique(): # loop through conditions\n",
    "    \n",
    "    print(condition_name)\n",
    "    tmp_list = []\n",
    "    \n",
    "    # go through each event and compute the sample/frame that it occurred on (b/c the list is currently in seconds)\n",
    "    for event in event_times_dict[condition_name]: # loop through events\n",
    "        tmp_list.append(get_tvec_sample(tvec, event))\n",
    "        \n",
    "    # once we go through converting each time to sample, and add to a list iteratively,\n",
    "    # store that list to its corresponding condition in the dictionary\n",
    "    event_samples_dict[condition_name] = tmp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_samples_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_samples_dict['access_period']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy and dictionary lesson: Let's analyze data from all trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove trials that have windows outside of entire recording, then extract data from each trial\n",
    "\n",
    "data_trial_dict = {}\n",
    "for condition_name in epoc_data['event_id_char'].unique(): # loop through conditions\n",
    "    \n",
    "    # initialize numpy array to populate with trial-extracted data\n",
    "    tmp_trial_array = np.empty([len(event_samples_dict[condition_name]), trial_window_num_samples])\n",
    "    \n",
    "    # use trial index template, offset with event sample, and extract trial data\n",
    "    for idx, event_sample in enumerate(event_samples_dict[condition_name]): # loop through events\n",
    "        tmp_trial_array[idx,:] = corrected_data[trial_template_indices + event_sample]\n",
    "    \n",
    "    # once data are fully populated, add to dictionary\n",
    "    data_trial_dict[condition_name] = tmp_trial_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_names = list(data_trial_dict.keys())\n",
    "\n",
    "plt.imshow(data_trial_dict[cond_names[0]], aspect='auto')\n",
    "plt.ylabel('Trial', fontsize=14)\n",
    "plt.xlabel('Sample', fontsize=14)\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Fluorescence', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tvec_trial, np.mean(data_trial_dict[cond_names[0]], axis=0))\n",
    "plt.plot(tvec_trial, np.mean(data_trial_dict[cond_names[1]], axis=0))\n",
    "plt.ylabel('Fluorescence', fontsize=14)\n",
    "plt.xlabel('Time', fontsize=14)\n",
    "plt.legend(cond_names, fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nape_python_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b42ec29e0d042ab71033bfd4ca780b7a8291c7b26e4c3b3923625b510f7afa3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
