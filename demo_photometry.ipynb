{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = r'D:\\non_2p\\adam\\2022_06_10_abb12'\n",
    "fname = '2022_06_10_abb12'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditions exercise 1: Detecting and loading data in different file formats.\n",
    "\n",
    "The cell below defines the absolute file path (`epoc_data_path`) for the behavioral data. Currently we are loading in the .feather file, which is just another file format that can store tabular data. In the sample_data folder, we also have a csv version - try changing the behavioral data path to the csv version, then edit the conditional in the following cell to load the csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoc_data_path = os.path.join(fdir, f'{fname}_events.feather')\n",
    "epoc_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'feather' in epoc_data_path:\n",
    "    print('loading feather file')\n",
    "    epoc_data = pd.read_feather(epoc_data_path)\n",
    "elif 'csv' in epoc_data_path:\n",
    "    print('loading csv file')\n",
    "    epoc_data = pd.read_csv(epoc_data_path)\n",
    "else:\n",
    "    print('Not a valid file type')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoc_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preview of the behavioral data table above doesn't really tell us how many behavioral conditions there are (event_id_char column). We can have python look through all entries in the event_id_char column and tell us what unique entries there are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "event_conditions = list(epoc_data['event_id_char'].unique()) # grab unique condition names\n",
    "event_conditions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditions exercise 2: Checking contents of lists using conditionals and boolean operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'access_period' in event_conditions and 'lick' in event_conditions:\n",
    "    print('Both conditions present')\n",
    "elif 'access_period' in event_conditions or 'lick' in event_conditions:\n",
    "    print('One out of the two conditions present')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas exercise 1: Exploring contents of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoc_data.nunique() # provides count of unique entries in each column\n",
    "epoc_data.info() # can identify if there is missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoc_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoc_data.iloc[95:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also get a sense of how many events (y dimension) there are. If we use the method `shape`, the first dimension outputted is y and the 2nd in x.\n",
    "epoc_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas exercise 2: Obtaining data from a dataframe column based on information in another column.\n",
    "\n",
    "We are working with neural activity data that was synchronized to events that happened during the recording. Our behavioral dataframe contains event times (event_ts) for two different types of behavooral events (access_periods and licks). Here let's figure out how to extract event times for a given condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab event times for condition 1\n",
    "event_one = epoc_data['event_ts'][epoc_data['event_id_char'] == 'access_period'].values\n",
    "event_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work on tseries data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas, math, and functions combined exercise: Correcting photometry traces with isosbestic channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(fdir, f'{fname}_streams_session.feather')\n",
    "\n",
    "data = pd.read_feather(data_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiber_id = '1' # 1 is NAcShell_medial; 2 is NAcShell_lateral\n",
    "\n",
    "data_405 = data['control'][data['fiber_id'] == fiber_id].values\n",
    "data_465 = data['signal'][data['fiber_id'] == fiber_id].values\n",
    "\n",
    "tvec = data['time'][data['fiber_id'] == fiber_id].values \n",
    "tvec_zeroed = tvec - data['time'][0] # for plotting trace starting from time 0\n",
    "\n",
    "fs = 1.0/np.mean(np.diff(tvec))\n",
    "\n",
    "print(tvec_zeroed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def controlFit(control, signal):\n",
    "    \n",
    "    # GuPPY version\n",
    "    # function to fit control channel to signal channel\n",
    "\n",
    "    p = np.polyfit(control, signal, 1)\n",
    "    arr = (p[0]*control)+p[1]\n",
    "    return arr\n",
    "\n",
    "\n",
    "def deltaFF(signal, control):\n",
    "    \n",
    "    # function to compute deltaF/F using fitted control channel and filtered signal channel\n",
    "\n",
    "    res = np.subtract(signal, control) # numerator of F(t)-f0\n",
    "    normData = np.divide(res, control) # (F(t)-f0)/F0\n",
    "    normData = normData*100\n",
    "\n",
    "    return normData\n",
    "\n",
    "fitted_control = controlFit(data_405, data_465) # this function would be helpful if we wanted to correct signals from multiple fluorophore channels\n",
    "corrected_data = deltaFF(data_465, fitted_control) # this function would be helpful everytime we needed to compute dF/F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(tvec_zeroed, data_405)\n",
    "plt.plot(tvec_zeroed, data_465)\n",
    "plt.plot(tvec_zeroed, fitted_control)\n",
    "plt.plot(tvec_zeroed, corrected_data)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Fluorescence')\n",
    "#plt.xlim([170, 400]) # we can zoom in to see how motion artifacts can be corrected for\n",
    "plt.legend(['405', '470', 'fit curve', 'corrected']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary Exercise: Dividing event times up into their respective conditions. These event times can then be organized into a dictionary for storage purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab event times for all conditions via for loop\n",
    "event_times_dict = {}\n",
    "for event_name in epoc_data['event_id_char'].unique():\n",
    "    event_times_dict[event_name] = epoc_data['event_ts'][epoc_data['event_id_char'] == event_name].values\n",
    "\n",
    "event_times_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert behavioral event times to samples: to prepare for indexing and snipping out trial activity windows.\n",
    "\n",
    "#### Requires knowledge on: dictionaries and functions \n",
    "\n",
    "The data itself is not characterized by units of time, rather each item in the vector is a \"sample\" in the recording and does not hold any information on timing\n",
    "\n",
    "On the other hand our behavioral events are in units of time. Accordingly, to extract trial snippits from the photometry data, we need to figure out which sample corresponds to a given event time\n",
    "\n",
    "We can use this line of code : `np.argmin(abs(tvec - time))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'First event from condition one: {event_one[0]}')\n",
    "\n",
    "print(f\"The sample that corresponds to {event_one[0]} is {np.argmin(abs(tvec - event_one[0]))}\")\n",
    "\n",
    "print(f\"Sample {np.argmin(abs(tvec - event_one[0]))}'s time: {tvec[4224]}\") # if dataset changes, replace number in tvec[4224] with calculated sample number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's extract the activity trace from one trial for demonstration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize start/end times for trial window\n",
    "event_window_time = np.array([-1, 10])\n",
    "event_window_samples = (event_window_time*fs).astype(int) # samples are integers\n",
    "\n",
    "# generate vector the maps time onto samples in the event trial\n",
    "trial_window_num_samples = event_window_samples[1] - event_window_samples[0]\n",
    "tvec_trial = np.linspace(event_window_time[0], event_window_time[1], trial_window_num_samples)\n",
    "\n",
    "# generate vector of every sample between start and end samples\n",
    "# then offset to specific event's window by adding the event sample\n",
    "trial_template_indices = np.arange(event_window_samples[0], event_window_samples[1])\n",
    "trial_samples = trial_template_indices + np.argmin(abs(tvec - event_one[0]))\n",
    "\n",
    "plt.plot(tvec_trial, corrected_data[trial_samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary lesson: To analyze all trials, let's do some organization of the event conditions and trial times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the above code into a function\n",
    "def get_tvec_sample(tvec, time):\n",
    "    return np.argmin(abs(tvec - time))\n",
    "\n",
    "event_samples_dict = {}\n",
    "for condition_name in epoc_data['event_id_char'].unique(): # loop through conditions\n",
    "    \n",
    "    print(condition_name)\n",
    "    tmp_list = []\n",
    "    \n",
    "    # go through each event and compute the sample/frame that it occurred on (b/c the list is currently in seconds)\n",
    "    for event in event_times_dict[condition_name]: # loop through events\n",
    "        tmp_list.append(get_tvec_sample(tvec, event))\n",
    "        \n",
    "    # once we go through converting each time to sample, and add to a list iteratively,\n",
    "    # store that list to its corresponding condition in the dictionary\n",
    "    event_samples_dict[condition_name] = tmp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_samples_dict['access_period']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy lesson: Let's analyze data from all trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove trials that have windows outside of entire recording, then extract data from each trial\n",
    "\n",
    "data_trial_dict = {}\n",
    "for condition_name in epoc_data['event_id_char'].unique(): # loop through conditions\n",
    "    \n",
    "    # initialize numpy array to populate with trial-extracted data\n",
    "    tmp_trial_array = np.empty([len(event_samples_dict[condition_name]), trial_window_num_samples])\n",
    "    \n",
    "    # use trial index template, offset with event sample, and extract trial data\n",
    "    for idx, event_sample in enumerate(event_samples_dict[condition_name]): # loop through events\n",
    "        tmp_trial_array[idx,:] = corrected_data[trial_template_indices + event_sample]\n",
    "    \n",
    "    # once data are fully populated, add to dictionary\n",
    "    data_trial_dict[condition_name] = tmp_trial_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_names = list(data_trial_dict.keys())\n",
    "\n",
    "plt.imshow(data_trial_dict[cond_names[0]], aspect='auto')\n",
    "plt.ylabel('Trial', fontsize=14)\n",
    "plt.xlabel('Sample', fontsize=14)\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Fluorescence', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tvec_trial, np.mean(data_trial_dict[cond_names[0]], axis=0))\n",
    "plt.plot(tvec_trial, np.mean(data_trial_dict[cond_names[1]], axis=0))\n",
    "plt.ylabel('Fluorescence', fontsize=14)\n",
    "plt.xlabel('Time', fontsize=14)\n",
    "plt.legend(cond_names, fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
